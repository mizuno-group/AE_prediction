{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate permutation importance (AUROC) for test compounds\n",
    "* Some datasets are not allowed to be uploaded.\n",
    "* Therefore, some datasets have been removed from publication environment.\n",
    "* The locations of the non-working without these datasets are commented out.\n",
    "* The output locations that differ from the publication environment are also commented out.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random as rnd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(target:str, file_split:str=\"\", file_X:str=\"\", file_y:str=\"\", file_filtered_feature:str=\"\", fillna:bool=True):\n",
    "    \"\"\" load x, y files \"\"\"\n",
    "    X = pd.read_pickle(file_X)\n",
    "    y = pd.read_pickle(file_y)\n",
    "    train_comp, test_comp = pd.read_pickle(file_split)\n",
    "    filtered_feature = pd.read_pickle(file_filtered_feature)\n",
    "    X_train = X.loc[train_comp, filtered_feature]\n",
    "    X_test = X.loc[test_comp, filtered_feature]\n",
    "    y_train = y.loc[train_comp, target]\n",
    "    y_test = y.loc[test_comp, target]\n",
    "    if fillna:\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "    X_train.columns = [str(i) for i in range(len(X_train.columns))]\n",
    "    X_test.columns = X_train.columns.tolist()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def preprocess(x_train:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame):\n",
    "    \"\"\" standalize / fillna with 0 \"\"\"\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(x_train)\n",
    "    x_train = pd.DataFrame(ss.transform(x_train), index=x_train.index, columns=x_train.columns).fillna(0)\n",
    "    x_test = pd.DataFrame(ss.transform(x_test), index=x_test.index, columns=x_test.columns).fillna(0)\n",
    "    return x_train, x_test\n",
    "\n",
    "# XGBoost\n",
    "def train(X:np.ndarray, y:np.ndarray, X_val:np.ndarray, y_val:np.ndarray, params:dict={}):\n",
    "    \"\"\" training \"\"\"\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    watchlist=[(dtrain,'train'),(dval,'eval')]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100000,\n",
    "        early_stopping_rounds=20,\n",
    "        evals=watchlist,\n",
    "        verbose_eval=0\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def test(X:np.ndarray, y:np.ndarray, model:xgb.core.Booster):\n",
    "    \"\"\" test \"\"\"\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    y_pred = model.predict(dtest)\n",
    "    score = 1 - roc_auc_score(y, y_pred)\n",
    "    return score\n",
    "\n",
    "class featureselect():\n",
    "    # permutation importance calculation with target data\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "        self.perm_imp = None\n",
    "        self.perm_imp_std = None\n",
    "        self.imp_features = None\n",
    "\n",
    "    def perm_selection(self, X:pd.core.frame.DataFrame, y:pd.core.frame.DataFrame, X_target:pd.core.frame.DataFrame, y_target:pd.core.frame.DataFrame, n_repeat:int=100, threshold:float=0, params:dict=dict(), stratify:bool=True, kfold:int=5):\n",
    "        \"\"\" feature selection with permutation importance method \"\"\"\n",
    "        self.__calc(X.values, y.values, X_target.values, y_target.values,\n",
    "                    n_repeat=n_repeat, params=copy.deepcopy(params),\n",
    "                    stratify=stratify, kfold=kfold)\n",
    "        features = X.columns.tolist()\n",
    "        perm_imp = pd.DataFrame([features]+[self.perm_imp, self.perm_imp_std], index=[\"feature\",\"importance\",\"importance_std\"]).T\n",
    "        imp_features = perm_imp[perm_imp['importance']>=threshold]['feature'].tolist()\n",
    "        self.imp_features = imp_features\n",
    "        print(\"{} / {} features extracted\".format(len(imp_features),len(features)))\n",
    "\n",
    "    def __calc(self, X:pd.core.frame.DataFrame, y:pd.core.frame.DataFrame, X_target:pd.core.frame.DataFrame, y_target:pd.core.frame.DataFrame, n_repeat:int=100, params:dict=dict(), stratify:bool=False, kfold:int=5):\n",
    "        \"\"\" calc permutation importance with metrics loss by n_repeat repeats\"\"\"\n",
    "        perm_imps=list()\n",
    "        if stratify:\n",
    "            kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "\n",
    "        for tr, val in kf.split(X, y):\n",
    "            X_train, y_train, X_val, y_val = X[tr,:], y[tr], X[val,:], y[val]\n",
    "            \n",
    "            model = train(X_train, y_train, X_val, y_val, params=params)\n",
    "            loss = test(X_target, y_target, model)\n",
    "            \n",
    "            X_tmp = copy.deepcopy(X_target)\n",
    "            agents = [i for i in range(len(X_target))]\n",
    "            for i in tqdm(range(len(X.T))):\n",
    "                perm_imp_tmp=list()\n",
    "                shuffle_lst = X_tmp[:,i]\n",
    "                for v in range(int(n_repeat)):\n",
    "                    rnd.shuffle(agents)\n",
    "                    X_target[:,i] = shuffle_lst[agents]\n",
    "                    loss_tmp = test(X_target, y_target, model)\n",
    "                    perm_imp_tmp.append(loss_tmp - loss)\n",
    "                \n",
    "                X_target[:,i] = shuffle_lst\n",
    "                perm_imps.append(perm_imp_tmp)\n",
    "        # UÂ‹\n",
    "        perm_imps = [[v for numb, v in enumerate(perm_imps) if numb%len(X_target.T)==i] for i in range(len(X_target.T))]\n",
    "        perm_imps = [list(itertools.chain(*i)) for i in perm_imps]\n",
    "        perm_imp = [np.mean(i) for i in perm_imps]\n",
    "        perm_imp_std = [np.std(i) for i in perm_imps]\n",
    "\n",
    "        # export\n",
    "        self.perm_imp = perm_imp\n",
    "        self.perm_imp_std = perm_imp_std\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 1e-5,\n",
    "    'max_delta_step': 5,\n",
    "    'lambda': 1e-5,\n",
    "    'alpha': 1e-5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.03,\n",
    "    'seed': 24771,\n",
    "    'n_jobs': -1\n",
    "    }  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "main_folder = \"\" # indicate mainfolder to which data files were exported to.\n",
    "\n",
    "file_X = f\"{main_folder}data/X.pickle\"\n",
    "file_y = f\"{main_folder}data/y.pickle\"\n",
    "target = 'Hepatobiliary disorders'\n",
    "target_folder=[\"drugbank_inter\", \"ctd_inter\", \"semmed_inter\", \"l1000\", \"mold2\", \"mol2vec\", \"mordred\", \"pubchem\", \"admet\", \"concat\"] # not-working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in target_folder:\n",
    "    print(folder)\n",
    "    df_res = pd.DataFrame()\n",
    "    output = f\"importance/xgb/date_{folder}.pickle\"\n",
    "    seed = 24771\n",
    "    for i in range(20):\n",
    "        file_filtered_feature = f\"{main_folder}data/filtered_feature/{folder}/date.pickle\"\n",
    "        file_split = f\"{main_folder}data/comp_split/date.pickle\"\n",
    "\n",
    "        x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=False)\n",
    "\n",
    "        # calc permutation importance\n",
    "        xgb_params['seed'] = seed\n",
    "        dat = featureselect()\n",
    "        dat.perm_selection(x, y, x_test, y_test, n_repeat=25, params=xgb_params, threshold=0, kfold=4)\n",
    "        # result\n",
    "        filtered_feature = pd.read_pickle(file_filtered_feature)\n",
    "        perm_imp = pd.DataFrame(dat.perm_imp, index=filtered_feature, columns=[str(i)])\n",
    "        df_res = pd.concat([df_res, perm_imp], axis=1, join=\"outer\")\n",
    "        seed+=10\n",
    "    pd.to_pickle(df_res, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no binding data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"concat_bind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame()\n",
    "output = f\"importance/xgb/date_{folder}.pickle\"\n",
    "seed = 24771\n",
    "for i in range(20):\n",
    "    file_filtered_feature = f\"{main_folder}data/filtered_feature/{folder}/date.pickle\"\n",
    "    file_split = f\"{main_folder}data/comp_split/date.pickle\"\n",
    "\n",
    "    x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=False)\n",
    "\n",
    "    # calc permutation importance\n",
    "    xgb_params['seed'] = seed\n",
    "    dat = featureselect()\n",
    "    dat.perm_selection(x, y, x_test, y_test, n_repeat=25, params=xgb_params, threshold=0, kfold=4)\n",
    "    # result\n",
    "    filtered_feature = pd.read_pickle(file_filtered_feature)\n",
    "    perm_imp = pd.DataFrame(dat.perm_imp, index=filtered_feature, columns=[str(i)])\n",
    "    df_res = pd.concat([df_res, perm_imp], axis=1, join=\"outer\")\n",
    "    seed+=10\n",
    "pd.to_pickle(df_res, output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b53935d5cbd3efb4eccc036f7c25f7b7fe7cf3075707571baeab5fe050364f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('faers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
