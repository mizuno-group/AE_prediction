{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Performance Evaluation\n",
    "* Some datasets are not allowed to be uploaded.\n",
    "* Therefore, some datasets have been removed from publication environment.\n",
    "* The locations of the non-working without these datasets are commented out.\n",
    "* The output locations that differ from the publication environment are also commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# tabnet\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Methods\n",
    "def tbn_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame,params:dict, seed:int=24771):\n",
    "    \"\"\"return tabnet prediction result\"\"\"\n",
    "    batch_size=128\n",
    "    max_epochs=500\n",
    "    params['seed']=seed\n",
    "    pretrainer = TabNetPretrainer(**params)\n",
    "    pretrainer.fit(X_train=x_train.values,eval_set=[x_train.values],max_epochs=max_epochs,\n",
    "                patience=10,batch_size=batch_size,virtual_batch_size=128,\n",
    "                drop_last=True)\n",
    "    model = TabNetClassifier(**params)\n",
    "    model.fit(X_train=x_train.values,y_train=y_train.values,eval_set=[(x_val.values,y_val.values)],eval_name=[\"valid\"],\n",
    "            eval_metric=[\"logloss\"],max_epochs=max_epochs,patience=10,\n",
    "            batch_size=batch_size,virtual_batch_size=128,\n",
    "            drop_last=False, from_unsupervised=pretrainer)\n",
    "    oof_pred = model.predict_proba(x_val.values)[:,1]\n",
    "    y_pred = model.predict_proba(x_test.values)[:,1]\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "def xgb_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, params:dict, seed:int=24771):\n",
    "    \"\"\"return xgboost prediction result\"\"\"\n",
    "    params['seed']=seed\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    dval = xgb.DMatrix(x_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(x_test)\n",
    "    evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        evals = evals,\n",
    "        early_stopping_rounds=20,\n",
    "        num_boost_round=10000,\n",
    "        verbose_eval=0,\n",
    "        )\n",
    "    oof_pred = model.predict(dval)\n",
    "    y_pred = model.predict(dtest)\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "def lgb_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, params:dict, seed:int=24771):\n",
    "    \"\"\"return lightgbm prediction result\"\"\"\n",
    "    params['seed']=seed\n",
    "    train_dataset = lgb.Dataset(x_train, y_train, params={'verbose': -1})\n",
    "    val_dataset = lgb.Dataset(x_val, y_val, params={'verbose': -1})\n",
    "    model = lgb.train(params = params, \n",
    "                        train_set = train_dataset, \n",
    "                        valid_sets = [train_dataset, val_dataset], \n",
    "                        num_boost_round = 10000, \n",
    "                        early_stopping_rounds = 20, \n",
    "                        verbose_eval = False,\n",
    "                        )\n",
    "    oof_pred = model.predict(x_val)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "def nb_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, params:dict, seed:int=24771):\n",
    "    \"\"\"return naive bayes prediction result\"\"\"\n",
    "    model = GaussianNB()\n",
    "    model.fit(x_train,y_train)\n",
    "    oof_pred = model.predict_proba(x_val)[:,1]\n",
    "    y_pred = model.predict_proba(x_test)[:,1]\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "def svm_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, params:dict, seed:int=24771):\n",
    "    \"\"\"return SVM prediction result\"\"\"\n",
    "    params['random_state']=seed\n",
    "    model = SVC(**params, probability=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    oof_pred = model.predict_proba(x_val)[:,1]\n",
    "    y_pred = model.predict_proba(x_test)[:,1]\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "def els_pred(x_train:pd.core.frame.DataFrame, y_train:pd.core.frame.DataFrame, x_val:pd.core.frame.DataFrame, y_val:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, params:dict, seed:int=24771):\n",
    "    \"\"\"return elastic net prediction result\"\"\"\n",
    "    params[\"random_state\"]=seed\n",
    "    model = ElasticNet(**params)\n",
    "    model.fit(x_train, y_train)\n",
    "    oof_pred = model.predict(x_val)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return oof_pred, y_pred\n",
    "\n",
    "# Parameters \n",
    "lgb_params=  {\n",
    "    \"num_leaves\": 2**5,\n",
    "    \"min_data_in_leaf\": 5,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"feature_fraction\": 0.7,\n",
    "    \"lambda_l1\": 1e-5,\n",
    "    \"lambda_l2\": 1e-5,\n",
    "    'boosting': 'gbdt',\n",
    "    \"objective\":\"binary\",\n",
    "    \"metric\":\"binary_logloss\",\n",
    "    \"learning_rate\":0.005,\n",
    "    'seed':24771,\n",
    "    'verbose':-1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 1e-5,\n",
    "    'max_delta_step': 5,\n",
    "    'lambda': 1e-5,\n",
    "    'alpha': 1e-5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.03,\n",
    "    'seed': 24771,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': 0.05,\n",
    "    'kernel':'sigmoid',\n",
    "    'degree': 5,\n",
    "    'gamma': 'auto',\n",
    "    'coef0': 0.4\n",
    "}\n",
    "\n",
    "tbn_params = {\n",
    "    'n_d':60,\n",
    "    'n_a':60,\n",
    "    'n_independent':2,\n",
    "    'n_shared':2,\n",
    "    'mask_type': 'sparsemax',\n",
    "    'n_steps': 1,\n",
    "    'gamma': 1.2,\n",
    "    'n_shared': 2,\n",
    "    'lambda_sparse': 1e-05,\n",
    "    'optimizer_fn':torch.optim.Adam, \n",
    "    'optimizer_params':dict(lr=2e-2),\n",
    "    'scheduler_params':dict(mode=\"min\",\n",
    "                            patience=5,\n",
    "                            min_lr=1e-7,\n",
    "                            factor=0.9),\n",
    "    'scheduler_fn':torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'verbose':0,\n",
    "    'device_name':\"cpu\"\n",
    "}\n",
    "\n",
    "els_params= {\n",
    "    'alpha':0.01,\n",
    "    'l1_ratio':0.2,\n",
    "    'max_iter':10000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "def preprocess(x_train:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame):\n",
    "    \"\"\" standalize / fillna with 0 \"\"\"\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(x_train)\n",
    "    x_train = pd.DataFrame(ss.transform(x_train), index=x_train.index, columns=x_train.columns).fillna(0)\n",
    "    x_test = pd.DataFrame(ss.transform(x_test), index=x_test.index, columns=x_test.columns).fillna(0)\n",
    "    return x_train, x_test\n",
    "\n",
    "def create_model(x:pd.core.frame.DataFrame, x_test:pd.core.frame.DataFrame, y:pd.core.frame.DataFrame, params:dict, method:Callable=\"\", seed:int=0):\n",
    "    \"\"\" prediction core module / 5-fold cross validation \"\"\"\n",
    "    # Create a KFold object\n",
    "    fold = StratifiedKFold(n_splits = 5, random_state = seed, shuffle = True)\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "\n",
    "    # Iterate through each fold\n",
    "    predictions = np.zeros(x_test.shape[0])\n",
    "    for trn_ind, val_ind in fold.split(x, y):\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        oof_pred, y_pred = method(x_train, y_train, x_val, y_val, x_test, params, seed=seed)\n",
    "        predictions += y_pred / 5\n",
    "        oof_predictions[val_ind] = oof_pred\n",
    "        gc.collect()\n",
    "    return oof_predictions, predictions\n",
    "\n",
    "def pred(method:Callable=\"\", params:dict=dict(), random_state:int=0, target:str=\"\", file_split:str=\"\", file_X:str=\"\", file_y:str=\"\", file_filtered_feature:str=\"\", fillna:bool=False):\n",
    "    \"\"\" repeat 5 times of predictions \"\"\"\n",
    "    x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=fillna)\n",
    "    oof_predictions = []\n",
    "    predictions = []\n",
    "    seed = random_state\n",
    "    for v in range(5):\n",
    "        oof_pred, pred = create_model(x, x_test, y, params, method=method, seed=seed)\n",
    "        oof_predictions.append(oof_pred)\n",
    "        predictions.append(pred)\n",
    "        seed += 1\n",
    "    return oof_predictions, predictions\n",
    "\n",
    "def calc_statistics(y_true:np.ndarray, y_pred:np.ndarray, threshold:float):\n",
    "    \"\"\" calculate performance \"\"\"\n",
    "    # For minus-AUPRC\n",
    "    rev_y_true = [1-i for i in y_true]\n",
    "    rev_y_pred = [1-i for i in y_pred]\n",
    "    # calculation\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    auroc = metrics.auc(fpr, tpr)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(rev_y_true, rev_y_pred)\n",
    "    minusauprc = metrics.auc(recall, precision)\n",
    "    # other scores\n",
    "    y_dammy = [1 if i>threshold else 0 for i in y_pred]\n",
    "    acc = metrics.accuracy_score(y_true, y_dammy)\n",
    "    f1 = metrics.matthews_corrcoef(y_true, y_dammy)\n",
    "    mcc = metrics.f1_score(y_true=y_true, y_pred=y_dammy)\n",
    "    return auroc, auprc, minusauprc, acc, f1, mcc\n",
    "\n",
    "def information(target:str=\"\", file_split:str=\"\", file_X:str=\"\", file_y:str=\"\", file_filtered_feature:str=\"\"):\n",
    "    \"\"\" extract sample informations \"\"\"\n",
    "    x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=False)\n",
    "    train_all = len(x.index)\n",
    "    train_p = sum(y)\n",
    "    train_n = train_all - train_p\n",
    "    test_all = len(x_test.index)\n",
    "    test_p = sum(y_test)\n",
    "    test_n = test_all - test_p\n",
    "    all_compounds = len(x.index)+len(x_test.index)\n",
    "    return (all_compounds, train_all, train_p, train_n, test_all, test_p, test_n)\n",
    "\n",
    "def load(target:str, file_split:str=\"\", file_X:str=\"\", file_y:str=\"\", file_filtered_feature:str=\"\", fillna:bool=True):\n",
    "    \"\"\" load x, y files \"\"\"\n",
    "    X = pd.read_pickle(file_X)\n",
    "    y = pd.read_pickle(file_y)\n",
    "    train_comp, test_comp = pd.read_pickle(file_split)\n",
    "    filtered_feature = pd.read_pickle(file_filtered_feature)\n",
    "    X_train = X.loc[train_comp, filtered_feature]\n",
    "    X_test = X.loc[test_comp, filtered_feature]\n",
    "    y_train = y.loc[train_comp, target]\n",
    "    y_test = y.loc[test_comp, target]\n",
    "    if fillna:\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "    X_train.columns = [str(i) for i in range(len(X_train.columns))]\n",
    "    X_test.columns = X_train.columns.tolist()\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main modules\n",
    "def main_date(method_def:Callable, params:dict=dict(), method:str=\"\", folder:str=\"\", fillna:bool=False, target=\"\"):\n",
    "    \"\"\" evaluate prediction scores with date split compounds \"\"\"\n",
    "    # path / cols for result\n",
    "    file_X = \"data/X.pickle\"\n",
    "    file_y = \"data/y.pickle\"\n",
    "    col = [\n",
    "        \"all_compounds\",\n",
    "        \"train_all\",\n",
    "        \"train_positive\",\n",
    "        \"train_negative\",\n",
    "        \"test_all\",\n",
    "        \"test_positive\",\n",
    "        \"test_negative\",\n",
    "        \"feature_number\",\n",
    "        \"model\",\n",
    "        \"threhold\",\n",
    "        \"auroc_oof\",\n",
    "        \"aupr_oof\",\n",
    "        \"minusauprc_oof\",\n",
    "        \"accuracy_oof\",\n",
    "        \"f1score_oof\",\n",
    "        \"mcc_oof\",\n",
    "        \"auroc_test\",\n",
    "        \"aupr_test\",\n",
    "        \"minusauprc_test\",\n",
    "        \"accuracy_test\",\n",
    "        \"f1score_test\",\n",
    "        \"mcc_test\",\n",
    "    ]\n",
    "    random_state=24771\n",
    "    df_res = pd.DataFrame(columns=col)\n",
    "    for i in tqdm(range(20)):\n",
    "        file_filtered_feature = f\"data/filtered_feature/{folder}/date.pickle\" # filtered feature file path\n",
    "        file_split = \"data/comp_split/date.pickle\" # date split file path\n",
    "\n",
    "        informations = information(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature)\n",
    "        feature_numbers = len(pd.read_pickle(file_filtered_feature))\n",
    "        preds = pred(method=method_def, params=params, random_state=random_state, target=target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=fillna)\n",
    "        x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=False)\n",
    "        # threshold\n",
    "        thresh=0.5\n",
    "        # calc scores\n",
    "        oof_preds = pd.DataFrame(preds[0]).mean().values\n",
    "        res_oof = calc_statistics(y, oof_preds, thresh)\n",
    "        y_preds = pd.DataFrame(preds[1]).mean().values\n",
    "        res_test = calc_statistics(y_test, y_preds, thresh)\n",
    "        res_all = [*informations, feature_numbers, method, thresh, *res_oof, *res_test]\n",
    "        df_res.loc[str(i),:] = res_all\n",
    "        random_state+=10\n",
    "    # output\n",
    "    df_res.to_pickle(\"evaluation/date/\"+method+\"_\"+folder+\".pickle\")\n",
    "    print(f\"finished : {method} / {folder}\")\n",
    "\n",
    "def main_random(method_def:Callable, params:dict=dict(), method:str=\"\", folder:str=\"\", fillna:bool=False, target=\"\"):\n",
    "    \"\"\" evaluate prediction scores with random split compounds \"\"\"\n",
    "    # path / cols for result\n",
    "    file_X = \"data/X.pickle\"\n",
    "    file_y = \"data/y.pickle\"\n",
    "    col = [\n",
    "        \"all_compounds\",\n",
    "        \"train_all\",\n",
    "        \"train_positive\",\n",
    "        \"train_negative\",\n",
    "        \"test_all\",\n",
    "        \"test_positive\",\n",
    "        \"test_negative\",\n",
    "        \"feature_number\",\n",
    "        \"model\",\n",
    "        \"threhold\",\n",
    "        \"auroc_oof\",\n",
    "        \"aupr_oof\",\n",
    "        \"minusauprc_oof\",\n",
    "        \"accuracy_oof\",\n",
    "        \"f1score_oof\",\n",
    "        \"mcc_oof\",\n",
    "        \"auroc_test\",\n",
    "        \"aupr_test\",\n",
    "        \"minusauprc_test\",\n",
    "        \"accuracy_test\",\n",
    "        \"f1score_test\",\n",
    "        \"mcc_test\",\n",
    "    ]\n",
    "    random_state=24771\n",
    "    df_res = pd.DataFrame(columns=col)\n",
    "    for i in tqdm(range(20)):\n",
    "        file_filtered_feature = f\"data/filtered_feature/{folder}/random_{str(i)}.pickle\" # filtered feature file path\n",
    "        file_split = f\"data/comp_split/random_{str(i)}.pickle\" # date split file path\n",
    "        informations = information(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature)\n",
    "        feature_numbers = len(pd.read_pickle(file_filtered_feature))\n",
    "        preds = pred(method=method_def, params=params, random_state=random_state, target=target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=fillna)\n",
    "        x, x_test, y, y_test = load(target, file_split=file_split, file_X=file_X, file_y=file_y, file_filtered_feature=file_filtered_feature, fillna=False)\n",
    "        # threshold\n",
    "        thresh=0.5\n",
    "        # calc scores\n",
    "        oof_preds = pd.DataFrame(preds[0]).mean().values\n",
    "        res_oof = calc_statistics(y, oof_preds, thresh)\n",
    "        y_preds = pd.DataFrame(preds[1]).mean().values\n",
    "        res_test = calc_statistics(y_test, y_preds, thresh)\n",
    "        res_all = [*informations, feature_numbers, method, thresh, *res_oof, *res_test]\n",
    "        df_res.loc[str(i),:] = res_all\n",
    "        random_state+=10\n",
    "\n",
    "    # output\n",
    "    df_res.to_pickle(\"evaluation/random/\"+method+\"_\"+folder+\".pickle\")\n",
    "    print(f\"finished : {method} / {folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date prediction\n",
    "* samples were splitted with date (by: 1_preparing.ipynb).\n",
    "* prediction scores will be calculated with 6 methods\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"drugbank\", \"ctd\", \"semmed\",\"drugbank_inter\", \"ctd_inter\", \"semmed_inter\", \"l1000\", \"mold2\", \"mol2vec\", \"mordred\", \"pubchem\", \"admet\", \"concat_bind\"] # not-working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lst = [\n",
    "    [xgb_pred, xgb_params, \"xgb\"],\n",
    "    [lgb_pred, lgb_params, \"lgb\"],\n",
    "]\n",
    "\n",
    "for i in pred_lst:\n",
    "    for folder in names:\n",
    "        main_date(i[0], params=i[1], method=i[2], folder=folder, fillna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lst = [\n",
    "    [els_pred, els_params, \"els\"],\n",
    "    [nb_pred, {}, \"nb\"],\n",
    "    [svm_pred, svm_params, \"svm\"],\n",
    "    [tbn_pred, tbn_params, \"tbn\"],\n",
    "]\n",
    "\n",
    "for i in pred_lst:\n",
    "    for folder in names:\n",
    "        main_date(i[0], params=i[1], method=i[2], folder=folder, fillna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random prediction\n",
    "* samples were splitted with random (by: 1_preparing.ipynb).\n",
    "* prediction scores will be calculated with 6 methods.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"drugbank\", \"ctd\", \"semmed\", \"l1000\", \"drugbank_inter\", \"ctd_inter\", \"semmed_inter\", \"mold2\", \"mol2vec\", \"mordred\", \"pubchem\", \"admet\"] # not-working\n",
    "pred_lst = [\n",
    "    [xgb_pred, xgb_params, \"xgb\"],\n",
    "    [lgb_pred, lgb_params, \"lgb\"],\n",
    "]\n",
    "\n",
    "for i in pred_lst:\n",
    "    for folder in names:\n",
    "        main_random(i[0], params=i[1], method=i[2], folder=folder, fillna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lst = [\n",
    "    [els_pred, els_params, \"els\"],\n",
    "    [nb_pred, {}, \"nb\"],\n",
    "    [svm_pred, svm_params, \"svm\"],\n",
    "    [tbn_pred, tbn_params, \"tbn\"],\n",
    "]\n",
    "\n",
    "for i in pred_lst:\n",
    "    for folder in names:\n",
    "        main_random(i[0], params=i[1], method=i[2], folder=folder, fillna=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b53935d5cbd3efb4eccc036f7c25f7b7fe7cf3075707571baeab5fe050364f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('faers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
